{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import namedtuple\n",
    "from NetworkModel import *\n",
    "from es import SimpleGA, CMAES, PEPG, OpenES, PEPGVariant \n",
    "from es import compute_ranks, compute_centered_ranks,compute_weight_decay\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "\tglobal NPARAMS\n",
    "\tglobal NPOPULATION\n",
    "\tglobal args \n",
    "\tglobal model_shapes\n",
    "\tglobal weight_decay_coef \n",
    "\n",
    "\n",
    "\ttorch.manual_seed(0)\n",
    "\tnp.random.seed(0)\n",
    "\tNPOPULATION=101  \n",
    "\tweight_decay_coef = 0.1\n",
    "\n",
    "\tArgs = namedtuple('Args', ['batch_size', 'test_batch_size', 'epochs', 'lr', 'cuda', 'seed', 'log_interval'])\n",
    "\targs = Args(batch_size=100, test_batch_size=1000, epochs=3, lr=0.001, cuda=False, seed=0, log_interval=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFeed():\n",
    "\tglobal train_loader\n",
    "\tglobal valid_loader\n",
    "\tglobal test_loader\n",
    "\n",
    "\tkwargs = {'num_workers': 1, 'pin_memory': False} if args.cuda else {}\n",
    "\n",
    "\ttrain_loader = torch.utils.data.DataLoader(datasets.MNIST('MNIST_data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "  \t\t\tbatch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\tvalid_loader = train_loader\n",
    "\n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "  \t\tdatasets.MNIST('MNIST_data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "  \t\t\tbatch_size=args.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debugSolver(es,printLog=True):\n",
    "\tbest_valid_acc = 0\n",
    "\ttraining_log=[]\n",
    "\tfor epoch in range(1, 10*args.epochs + 1):\n",
    "\t  # train loop\n",
    "\t  model.eval()\n",
    "\t  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\t    data, target = Variable(data), Variable(target)\n",
    "\t    solutions = es.ask() \n",
    "\t    reward = np.zeros(es.popsize)\n",
    "\t    for i in range(es.popsize):\n",
    "\t      update_model(solutions[i], model, model_shapes)\n",
    "\t      output = model(data)\n",
    "\t      loss = F.nll_loss(output, target) # loss function used = =  \n",
    "\t      reward[i] = -loss.data[0]\n",
    "\t    best_raw_reward = reward.max()\n",
    "\t    reward = compute_centered_ranks(reward)\n",
    "\t    l2_decay = compute_weight_decay(weight_decay_coef, solutions)\n",
    "\t    reward += l2_decay\n",
    "\t    es.tell(reward)\n",
    "\t    result = es.result()\n",
    "\t    if (batch_idx % 50 == 0) and printLog:\n",
    "\t    \tprint(epoch, batch_idx, best_raw_reward,result[1]) \n",
    "\t  curr_solution = es.current_param()\n",
    "\t  update_model(curr_solution, model, model_shapes)\n",
    "\t  valid_acc = evaluate(model, valid_loader, print_mode=False)\n",
    "\t  training_log.append(valid_acc) \n",
    "\t  print('valid_acc', valid_acc * 100.)\n",
    "\t  if valid_acc >= best_valid_acc:\n",
    "\t    best_valid_acc = valid_acc\n",
    "\t    best_model = copy.deepcopy(model)\n",
    "\t    print('best valid_acc', best_valid_acc * 100.)\n",
    "\treturn training_log,best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config()\n",
    "model=Net()\n",
    "NPARAMS,model_shapes=cal_nparams(model)\n",
    "dataFeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pepg = PEPG(NPARAMS,                         # number of model parameters\n",
    "\t    sigma_init=0.01,                  # initial standard deviation\n",
    "\t    learning_rate=0.1,               # learning rate for standard deviation\n",
    "\t    learning_rate_decay=1.0,       # don't anneal the learning rate\n",
    "\t    popsize=NPOPULATION,             # population size\n",
    "\t    average_baseline=False,          # set baseline to average of batch\n",
    "\t    weight_decay=0.00,            # weight decay coefficient\n",
    "\t    rank_fitness=False,           # use rank rather than fitness numbers\n",
    "\t    forget_best=False)            # don't keep the historical best solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pepg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pepgv = PEPGVariant(NPARAMS,                         # number of model parameters\n",
    "\t    sigma_init=0.01,                  # initial standard deviation\n",
    "\t    learning_rate=0.1,               # learning rate for standard deviation\n",
    "\t    learning_rate_decay=1.0,       # don't anneal the learning rate\n",
    "\t    popsize=NPOPULATION,             # population size\n",
    "\t    average_baseline=False,          # set baseline to average of batch\n",
    "\t    weight_decay=0.00,            # weight decay coefficient\n",
    "\t    rank_fitness=False,           # use rank rather than fitness numbers\n",
    "\t    forget_best=False)            # don't keep the historical best solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEPG_history,best_model=debugSolver(pepg,printLog=True)\n",
    "PEPGV_history,best_model=debugSolver(pepgv,printLog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
