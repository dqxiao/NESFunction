{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cma\n",
    "import random \n",
    "from es import SimpleGA, CMAES, PEPG, OpenES, PEPGVariant, SlideWindow,Adam\n",
    "\n",
    "from testbed import * \n",
    "import pickle \n",
    "import multiprocessing as mp\n",
    "import copy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calProduct(x): \n",
    "    _x=np.log(x)\n",
    "    return np.exp(_x.sum())\n",
    "\n",
    "def calEntropy(x):\n",
    "    _x=np.log(x)\n",
    "    return _x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squareSum(x):\n",
    "    return -1*np.square(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "\tglobal NPARAMS\n",
    "\tglobal NPOPULATION\n",
    "\tglobal MAX_ITERATION\n",
    "\tglobal fit_func\n",
    "\n",
    "\tNPARAMS = 32    # make this a 100-dimensinal problem.\n",
    "\tNPOPULATION = 101    # use population size of 101.\n",
    "\tMAX_ITERATION = 80000 # run each solver for 5000 generations.\n",
    "# \tfit_func=rastrigin\n",
    "# \tfit_func = dejong\n",
    "\t# fit_func = hyperEllipsoid\n",
    "# \tfit_func =schwefel\n",
    "# \tfit_func =griewangk\n",
    "\tfit_func = rosebrock\n",
    "# \tfit_func = squareSum\n",
    "\n",
    "\tNPOPULATION=int(4+3*np.ceil(np.log(NPARAMS))) # setting as approximate \n",
    "\tNPOPULATION= int(NPOPULATION/2)*2+1\n",
    "\tnp.random.seed(0)\n",
    "\trandom.seed(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "17\n",
      "<function rosebrock at 0x000002CCF3973268>\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "config()\n",
    "print(NPARAMS)\n",
    "print(NPOPULATION)\n",
    "print(fit_func)\n",
    "print(fit_func([0.0,0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PEPGAdaptive:\n",
    "  '''Extension of PEPG with adaptive diversity_base'''\n",
    "\n",
    "  def __init__(self, num_params,             # number of model parameters\n",
    "               sigma_init=0.10,              # initial standard deviation\n",
    "               sigma_alpha=0.20,             # learning rate for standard deviation\n",
    "               sigma_decay=0.999,            # anneal standard deviation\n",
    "               sigma_limit=0.01,             # stop annealing if less than this\n",
    "               sigma_max_change=0.2,         # clips adaptive sigma to 20%\n",
    "               learning_rate=0.01,           # learning rate for standard deviation\n",
    "               learning_rate_decay = 0.9999, # annealing the learning rate\n",
    "               learning_rate_limit = 0.01,   # stop annealing learning rate\n",
    "               elite_ratio = 0,              # if > 0, then ignore learning_rate\n",
    "               popsize=256,                  # population size\n",
    "               average_baseline=True,        # set baseline to average of batch\n",
    "               weight_decay=0.01,            # weight decay coefficient\n",
    "               rank_fitness=True,            # use rank rather than fitness numbers\n",
    "               diversity_base=0.1,\n",
    "               option = 0,                   # 0: default selection _sigma, 1: huan version without sigma \n",
    "               forget_best=True):            # don't keep the historical best solution\n",
    "\n",
    "    self.num_params = num_params\n",
    "    self.sigma_init = sigma_init\n",
    "    self.sigma_alpha = sigma_alpha\n",
    "    self.sigma_decay = sigma_decay\n",
    "    self.sigma_limit = sigma_limit\n",
    "    self.sigma_max_change = sigma_max_change\n",
    "    self.learning_rate = learning_rate\n",
    "    self.learning_rate_decay = learning_rate_decay\n",
    "    self.learning_rate_limit = learning_rate_limit\n",
    "    self.popsize = popsize\n",
    "    self.average_baseline = average_baseline\n",
    "    self.diversity_base = diversity_base  # Can i get the basic idea to run\n",
    "    self.option = option\n",
    "\n",
    "    if self.average_baseline:\n",
    "      assert (self.popsize % 2 == 0), \"Population size must be even\"\n",
    "      self.batch_size = int(self.popsize / 2)\n",
    "    else:\n",
    "      assert (self.popsize & 1), \"Population size must be odd\"\n",
    "      self.batch_size = int((self.popsize - 1) / 2)\n",
    "\n",
    "    # option to use greedy es method to select next mu, rather than using drift param\n",
    "    self.elite_ratio = elite_ratio\n",
    "    self.elite_popsize = int(self.popsize * self.elite_ratio)\n",
    "    self.use_elite = False\n",
    "    if self.elite_popsize > 0:\n",
    "      self.use_elite = True\n",
    "\n",
    "    self.forget_best = forget_best\n",
    "    self.batch_reward = np.zeros(self.batch_size * 2)\n",
    "    #\n",
    "    self.mu = np.zeros(self.num_params)\n",
    "    self.sigma = np.ones(self.num_params) * self.sigma_init\n",
    "    self.curr_best_mu = np.zeros(self.num_params)\n",
    "    self.best_mu = np.zeros(self.num_params)\n",
    "    self.best_reward = 0\n",
    "    self.first_interation = True\n",
    "    self.weight_decay = weight_decay\n",
    "    self.rank_fitness = rank_fitness\n",
    "    if self.rank_fitness:\n",
    "      self.forget_best = True # always forget the best one if we rank\n",
    "    # choose optimizer\n",
    "    self.optimizer = Adam(self, learning_rate)\n",
    "    self.rewardWindow=SlideWindow(num_params) # adaptive diversity function  \n",
    "    self.entropyWindow=SlideWindow(num_params)  # adaptive diversity function \n",
    "    self.diversityWindow =SlideWindow(4)  # recording the history diversity  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def rms_stdev(self):\n",
    "    sigma = self.sigma\n",
    "    return np.mean(np.sqrt(sigma*sigma))\n",
    "\n",
    "  def ask(self):\n",
    "    '''returns a list of parameters'''\n",
    "    # antithetic sampling\n",
    "    self.epsilon = np.random.randn(self.batch_size, self.num_params) * self.sigma.reshape(1, self.num_params)\n",
    "    self.epsilon_full = np.concatenate([self.epsilon, - self.epsilon])\n",
    "    if self.average_baseline:\n",
    "      epsilon = self.epsilon_full\n",
    "    else:\n",
    "      # first population is mu, then positive epsilon, then negative epsilon\n",
    "      epsilon = np.concatenate([np.zeros((1, self.num_params)), self.epsilon_full])\n",
    "    solutions = self.mu.reshape(1, self.num_params) + epsilon\n",
    "    self.solutions = solutions\n",
    "    return solutions\n",
    "\n",
    "  def tell(self, reward_table_result):\n",
    "    # input must be a numpy float array\n",
    "    assert(len(reward_table_result) == self.popsize), \"Inconsistent reward_table size reported.\"\n",
    "\n",
    "    reward_table = np.array(reward_table_result)\n",
    "    \n",
    "    if self.rank_fitness:\n",
    "      reward_table = compute_centered_ranks(reward_table)\n",
    "    \n",
    "    if self.weight_decay > 0:\n",
    "      l2_decay = compute_weight_decay(self.weight_decay, self.solutions)\n",
    "      reward_table += l2_decay\n",
    "\n",
    "    reward_offset = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if self.average_baseline:\n",
    "      b = np.mean(reward_table)\n",
    "      reward_offset = 0\n",
    "    else:\n",
    "      b = reward_table[0] # baseline\n",
    "      \n",
    "    reward = reward_table[reward_offset:]\n",
    "\n",
    "    self.rewardWindow.update(np.array(reward).mean())\n",
    "    self.entropyWindow.update(calEntropy(self.sigma)) # thanks  \n",
    "\n",
    "    if self.use_elite:\n",
    "      idx = np.argsort(reward)[::-1][0:self.elite_popsize]\n",
    "    else:\n",
    "      idx = np.argsort(reward)[::-1]\n",
    "\n",
    "    best_reward = reward[idx[0]]\n",
    "    if (best_reward > b or self.average_baseline):\n",
    "      best_mu = self.mu + self.epsilon_full[idx[0]]\n",
    "      best_reward = reward[idx[0]]\n",
    "    else:\n",
    "      best_mu = self.mu\n",
    "      best_reward = b\n",
    "\n",
    "    self.curr_best_reward = best_reward\n",
    "    self.curr_best_mu = best_mu\n",
    "\n",
    "    if self.first_interation:\n",
    "      self.sigma = np.ones(self.num_params) * self.sigma_init\n",
    "      self.first_interation = False\n",
    "      self.best_reward = self.curr_best_reward\n",
    "      self.best_mu = best_mu\n",
    "    else:\n",
    "      if self.forget_best or (self.curr_best_reward > self.best_reward):\n",
    "        self.best_mu = best_mu\n",
    "        self.best_reward = self.curr_best_reward\n",
    "\n",
    "    # short hand\n",
    "    epsilon = self.epsilon\n",
    "    sigma = self.sigma\n",
    "\n",
    "    # update the mean\n",
    "\n",
    "    # move mean to the average of the best idx means\n",
    "    if self.use_elite:\n",
    "      self.mu += self.epsilon_full[idx].mean(axis=0)\n",
    "    else:\n",
    "      rT = (reward[:self.batch_size] - reward[self.batch_size:])\n",
    "      change_mu = np.dot(rT, epsilon)\n",
    "      self.optimizer.stepsize = self.learning_rate\n",
    "      update_ratio = self.optimizer.update(-change_mu) # adam, rmsprop, momentum, etc.\n",
    "      #self.mu += (change_mu * self.learning_rate) # normal SGD method\n",
    "\n",
    "    # adaptive sigma\n",
    "    # normalization\n",
    "\n",
    "    if (self.sigma_alpha > 0):\n",
    "      stdev_reward = 1.0\n",
    "      if not self.rank_fitness:\n",
    "        stdev_reward = reward.std()\n",
    "      \n",
    "      S = ((epsilon * epsilon - (sigma * sigma).reshape(1, self.num_params)) / sigma.reshape(1, self.num_params))\n",
    "      reward_avg = (reward[:self.batch_size] + reward[self.batch_size:]) / 2.0\n",
    "      rS = reward_avg - b\n",
    "      \n",
    "      \n",
    "      delta_sigma = (np.dot(rS, S)) / (2 * self.batch_size * stdev_reward)\n",
    "      \n",
    "\n",
    "      # adjust sigma according to the adaptive sigma calculation\n",
    "      # for stability, don't let sigma move more than 10% of orig value\n",
    "      change_sigma = self.sigma_alpha * delta_sigma\n",
    "      change_sigma = np.minimum(change_sigma, self.sigma_max_change * self.sigma)\n",
    "      change_sigma = np.maximum(change_sigma, - self.sigma_max_change * self.sigma)\n",
    "      \n",
    "      flag= np.all(np.isnan(change_sigma))\n",
    "\n",
    "      self.diversity_best=self.diversity_base\n",
    "#       if self.rewardWindow.evident():\n",
    "#         diversity_bound = self.rewardWindow.lastDiff()/self.entropyWindow.lastDiff()  # be positive \n",
    "#         self.diversity_best = min (self.diversity_best, diversity_bound)\n",
    "#         self.diversity_best = max (0,self.diversity_best)\n",
    "#         if self.rewardWindow.lastDiff()<-self.rewardWindow.std() or self.entropyWindow.lastDiff()<0:\n",
    "#             self.diversity_best = 0\n",
    "#       if self.option==0:\n",
    "#         self.sigma += self.learning_rate*self.diversity_best\n",
    "#       if self.option==1:\n",
    "#         self.sigma += self.sigma*self.learning_rate*self.diversity_best\n",
    "#       if self \n",
    "      self.sigma += np.power(self.sigma, self.option)*self.learning_rate*self.diversity_best\n",
    "\n",
    "        \n",
    "    # done \n",
    "      self.sigma += change_sigma\n",
    "      self.diversityWindow.update(self.diversity_best)\n",
    "\n",
    "    \n",
    "#     if all(self.sigma：\n",
    "#         self.sigma =  np.ones(self.num_params) * self.sigma_init/1000000000\n",
    "    self.sigma =abs(self.sigma)\n",
    "\n",
    "    if (self.sigma_decay < 1 ):\n",
    "      self.sigma[self.sigma > self.sigma_limit] *= self.sigma_decay\n",
    "    \n",
    "    if (self.learning_rate_decay < 1 and self.learning_rate > self.learning_rate_limit):\n",
    "      self.learning_rate *= self.learning_rate_decay\n",
    "\n",
    "  def current_param(self):\n",
    "    return self.curr_best_mu\n",
    "\n",
    "  def set_mu(self, mu):\n",
    "    self.mu = np.array(mu)\n",
    "  \n",
    "  def best_param(self):\n",
    "    return self.best_mu\n",
    "\n",
    "  def result(self): # return best params so far, along with historically best reward, curr reward, sigma\n",
    "    return (self.best_mu, self.best_reward, self.curr_best_reward, self.sigma, self.diversity_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_solver(solver,printLog=True):\n",
    "\thistory = []\n",
    "\tfor j in range(MAX_ITERATION):\n",
    "\t\tsolutions = solver.ask()\n",
    "\t\tfitness_list = np.zeros(solver.popsize)\n",
    "\t\tfor i in range(solver.popsize):\n",
    "\t\t\tfitness_list[i] = fit_func(solutions[i])\n",
    "\t\tsolver.tell(fitness_list)\n",
    "\t\tresult = solver.result() # first element is the best solution, second element is the best fitness\n",
    "\t\thistory.append(abs(result[1]))\n",
    "\t\tif (j+1) % 5000 == 0 and printLog:\n",
    "\t\t  print(\"fitness at iteration\", (j+1), result[1])\n",
    "\t# print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "\tprint(\"fitness score at this local optimum:\", result[1])\n",
    "\treturn history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_debug_solver(solver,printLog=True,evaluation=30):\n",
    "    result=[]\n",
    "    #solver_copy=copy.copy(solver)\n",
    "    for j in range(evaluation):\n",
    "        es=copy.deepcopy(solver)\n",
    "        _,history=debug_solver(es,printLog=printLog)\n",
    "        result.append(history)\n",
    "    return np.array(result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_solver(solver,printLog=True):\n",
    "\thistory_population=[]\n",
    "\thistory=[]\n",
    "\tx = np.random.randn(NPARAMS)\n",
    "\tfor j in range(MAX_ITERATION):\n",
    "\t\tsolutions =solver.ask()\n",
    "\t\tfitness_list = np.zeros(solver.popsize)\n",
    "\t\tfor i in range(solver.popsize):\n",
    "\t\t\tfitness_list[i]=fit_func(solutions[i])\n",
    "\t\tsolver.tell(fitness_list)\n",
    "\t\tresult =solver.result()\n",
    "\t\tif ((j+1)%1000 ==0 or j==0) and printLog:\n",
    "\t\t\tprint(\"fitness at iteration\",(j+1),fitness_list.mean(),result[1])\n",
    "# \t\tif j%10!=0:\n",
    "# \t\t\tcontinue \n",
    "\t\thistory_population.append(solutions)\n",
    "\t\tif len(result)==4:\n",
    "\t\t\thistory.append([abs(result[1]),abs(fitness_list.mean()),calEntropy(result[3]),abs(fitness_list.std())])\n",
    "\t\telse:\n",
    "\t\t\thistory.append([abs(result[1]),abs(fitness_list.mean()),calEntropy(result[3]),abs(fitness_list.std()),result[-1]])            \n",
    "\tprint(\"fitness score at this local optimum:\",result[1])\n",
    "\treturn history_population,np.array(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fitness of initial guess -16007.2118865\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(NPARAMS)\n",
    "print(\"The fitness of initial guess\", fit_func(x)) \n",
    "print(NPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "from collections import namedtuple\n",
    "def pickle_write(data,method,fname):\n",
    "    pickle_out=open(method+fname+\".pickle\",\"wb\")\n",
    "    cloudpickle.dump(data,pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "\n",
    "def readData(name):\n",
    "\tpickle_in=open(name+\".pickle\",\"rb\")\n",
    "\tdata=cloudpickle.load(pickle_in)\n",
    "\treturn data \n",
    "\n",
    "Config=namedtuple('configuration',['popsize','learning_rate','sigma_init','diversity_base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curvePlot(historys,labelName,start,end):\n",
    "    epoch=np.linspace(start,end+1,end-start)\n",
    "    x=np.max(historys[:,start:end],axis=0)\n",
    "    y=np.min(historys[:,start:end],axis=0)\n",
    "    #print(x.shape)\n",
    "#     plt.fill_between(epoch,x,y,alpha=0.5)\n",
    "#     \"\"\n",
    "#     for index in range(30):\n",
    "#         plt.plot(epoch,historys[index,start:end],linewidth=1.0,linestyle=\"-\",alpha=0.2,color='black')\n",
    "    avg_line,=plt.plot(epoch,np.mean(historys[:,start:end],axis=0),linewidth=1.0,linestyle=\"-\",label=labelName)\n",
    "    \n",
    "    return avg_line \n",
    "\n",
    "def title_gen(args):\n",
    "    return \"{}-{} P:{}\".format(args.func,args.dimension, args.popsize)\n",
    "\n",
    "def label_gen(config,method):\n",
    "    return \"{}-lr:{}-{}-{}\".format(method,config.learning_rate, config.sigma_init,config.diversity_base)\n",
    "\n",
    "def setPlot(logs, method,index):\n",
    "    lgs=[] # for legends \n",
    "    for config in logs.keys():\n",
    "        label=label_gen(config,method)\n",
    "        h=logs[config]\n",
    "        tline=curvePlot(h[:,:,index],label,start,end)\n",
    "        lgs.append(copy.copy(tline))\n",
    "\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')\n",
    "#     plt.title(title_gen(args))\n",
    "    plt.legend(handles=lgs, loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness score at this local optimum: -0.0314776891986\n",
      "fitness score at this local optimum: -0.0580554235824\n",
      "fitness score at this local optimum: -0.029386457522\n",
      "fitness score at this local optimum: -0.0366954867632\n",
      "fitness score at this local optimum: -0.0561364599877\n",
      "fitness score at this local optimum: -0.0557404042058\n",
      "fitness score at this local optimum: -0.0142542735837\n",
      "fitness score at this local optimum: -0.0285388533258\n",
      "fitness score at this local optimum: -0.0424541330684\n",
      "fitness score at this local optimum: -0.0559525106168\n",
      "fitness score at this local optimum: -0.0476571299063\n",
      "fitness score at this local optimum: -0.0558555369008\n",
      "fitness score at this local optimum: -0.0513484013023\n",
      "fitness score at this local optimum: -0.0418536562551\n",
      "fitness score at this local optimum: -0.0537019514048\n",
      "fitness score at this local optimum: -0.0386939173303\n",
      "fitness score at this local optimum: -0.0619894584362\n",
      "fitness score at this local optimum: -0.0473122466334\n",
      "fitness score at this local optimum: -0.0321922615675\n",
      "fitness score at this local optimum: -0.0495918155579\n",
      "fitness score at this local optimum: -0.0310767888012\n",
      "fitness score at this local optimum: -0.0421959214098\n",
      "fitness score at this local optimum: -0.0292511105371\n",
      "fitness score at this local optimum: -0.0481305637206\n",
      "fitness score at this local optimum: -0.0483670668479\n",
      "fitness score at this local optimum: -0.0552197265841\n",
      "fitness score at this local optimum: -0.0371969749405\n",
      "fitness score at this local optimum: -0.0336135290129\n",
      "fitness score at this local optimum: -0.0425143999149\n",
      "fitness score at this local optimum: -0.045329548197\n",
      "=====================================================================\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import copy \n",
    "pepgLogs=dict()\n",
    "for sigma_init_val in [0.1]:\n",
    "    for lr in [0.01]:\n",
    "        pepg = PEPG(NPARAMS,                         # number of model parameters\n",
    "\t    sigma_init=sigma_init_val,                 # initial standard deviation\n",
    "\t    learning_rate=lr ,             # learning rate for standard deviation\n",
    "\t    learning_rate_decay=0.9999,       # don't anneal the learning rate\n",
    "\t    popsize=NPOPULATION,             # population size\n",
    "\t    average_baseline=False,          # set baseline to average of batch\n",
    "\t    weight_decay=0.00,            # weight decay coefficient\n",
    "\t    rank_fitness=False,           # use rank rather than fitness numbers\n",
    "\t    forget_best=False)  \n",
    "        \n",
    "        h= batch_debug_solver(pepg,printLog=False)\n",
    "        print(\"=====================================================================\")\n",
    "        config=Config(popsize=NPOPULATION, learning_rate=lr, sigma_init=sigma_init_val,diversity_base=0)\n",
    "        pepgLogs[config]=copy.copy(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness score at this local optimum: -0.540465989144\n",
      "fitness score at this local optimum: -0.355815878259\n",
      "fitness score at this local optimum: -0.556282821157\n",
      "fitness score at this local optimum: -0.671490895206\n",
      "fitness score at this local optimum: -0.439818498763\n",
      "fitness score at this local optimum: -0.477098841811\n",
      "fitness score at this local optimum: -0.428717102554\n",
      "fitness score at this local optimum: -0.401209779811\n",
      "fitness score at this local optimum: -0.491513948828\n",
      "fitness score at this local optimum: -0.65662325529\n",
      "fitness score at this local optimum: -0.61758677181\n",
      "fitness score at this local optimum: -0.448386197179\n",
      "fitness score at this local optimum: -0.565506807341\n",
      "fitness score at this local optimum: -0.471365277767\n",
      "fitness score at this local optimum: -0.52029490183\n",
      "fitness score at this local optimum: -0.57087773271\n",
      "fitness score at this local optimum: -0.539569526968\n",
      "fitness score at this local optimum: -0.502511764839\n",
      "fitness score at this local optimum: -0.385517810179\n",
      "fitness score at this local optimum: -0.586293926329\n",
      "fitness score at this local optimum: -0.53173789046\n",
      "fitness score at this local optimum: -0.528777485056\n",
      "fitness score at this local optimum: -0.485090069971\n",
      "fitness score at this local optimum: -0.686536553181\n",
      "fitness score at this local optimum: -0.642862518523\n",
      "fitness score at this local optimum: -0.497712579963\n",
      "fitness score at this local optimum: -0.462915476066\n",
      "fitness score at this local optimum: -0.499401884697\n",
      "fitness score at this local optimum: -0.364263389882\n",
      "fitness score at this local optimum: -0.405547556797\n",
      "=====================================================================\n",
      "fitness score at this local optimum: -0.0628094620331\n",
      "fitness score at this local optimum: -0.0807781639139\n",
      "fitness score at this local optimum: -0.127287001923\n",
      "fitness score at this local optimum: -0.0252923594567\n",
      "fitness score at this local optimum: -0.0774360374152\n",
      "fitness score at this local optimum: -0.148193562367\n",
      "fitness score at this local optimum: -0.0431763262993\n",
      "fitness score at this local optimum: -0.1486399931\n",
      "fitness score at this local optimum: -0.0848188597092\n",
      "fitness score at this local optimum: -0.0731000207994\n",
      "fitness score at this local optimum: -2.57587828753e-05\n",
      "fitness score at this local optimum: -0.208216653064\n",
      "fitness score at this local optimum: -0.0645410916782\n",
      "fitness score at this local optimum: -0.123554810904\n",
      "fitness score at this local optimum: -0.0781746752703\n",
      "fitness score at this local optimum: -0.156966698227\n",
      "fitness score at this local optimum: -0.130817779956\n",
      "fitness score at this local optimum: -0.151484394937\n",
      "fitness score at this local optimum: -0.0642140506145\n",
      "fitness score at this local optimum: -0.147091159833\n",
      "fitness score at this local optimum: -0.120557290873\n",
      "fitness score at this local optimum: -0.165365774679\n",
      "fitness score at this local optimum: -0.115657552198\n",
      "fitness score at this local optimum: -0.13243855001\n",
      "fitness score at this local optimum: -0.128439665722\n",
      "fitness score at this local optimum: -0.00120133090172\n",
      "fitness score at this local optimum: -0.0724448593382\n",
      "fitness score at this local optimum: -0.124524531356\n",
      "fitness score at this local optimum: -0.111815166324\n",
      "fitness score at this local optimum: -0.160238260582\n",
      "=====================================================================\n",
      "fitness score at this local optimum: -0.0372152141126\n",
      "fitness score at this local optimum: -0.0412759026294\n",
      "fitness score at this local optimum: -0.0398831803058\n",
      "fitness score at this local optimum: -0.0485173000133\n",
      "fitness score at this local optimum: -0.0584205890481\n",
      "fitness score at this local optimum: -0.0336961398116\n",
      "fitness score at this local optimum: -0.0315509385514\n",
      "fitness score at this local optimum: -0.042227659506\n",
      "fitness score at this local optimum: -0.0696606789704\n",
      "fitness score at this local optimum: -0.0361149983443\n",
      "fitness score at this local optimum: -0.0347882089442\n",
      "fitness score at this local optimum: -0.0517100804539\n",
      "fitness score at this local optimum: -0.0534938853787\n",
      "fitness score at this local optimum: -0.0384477166198\n",
      "fitness score at this local optimum: -0.0447158536576\n",
      "fitness score at this local optimum: -0.0460404287659\n",
      "fitness score at this local optimum: -0.0617653783824\n",
      "fitness score at this local optimum: -0.0474418917707\n",
      "fitness score at this local optimum: -0.0544019496376\n",
      "fitness score at this local optimum: -0.053375512635\n",
      "fitness score at this local optimum: -0.0301475777516\n",
      "fitness score at this local optimum: -0.0597376772531\n",
      "fitness score at this local optimum: -0.0593520335544\n",
      "fitness score at this local optimum: -0.0493792941697\n",
      "fitness score at this local optimum: -0.0362447829571\n",
      "fitness score at this local optimum: -0.0437697159156\n",
      "fitness score at this local optimum: -0.0429689236368\n",
      "fitness score at this local optimum: -0.0351201206312\n",
      "fitness score at this local optimum: -0.0374505089391\n",
      "fitness score at this local optimum: -0.0361054944211\n",
      "=====================================================================\n",
      "fitness score at this local optimum: -0.0745522788212\n",
      "fitness score at this local optimum: -0.0497488138322\n",
      "fitness score at this local optimum: -0.0711902556819\n",
      "fitness score at this local optimum: -0.0411161367506\n",
      "fitness score at this local optimum: -0.0598662699798\n",
      "fitness score at this local optimum: -0.0376560985368\n",
      "fitness score at this local optimum: -0.0542432851005\n",
      "fitness score at this local optimum: -0.050384518266\n",
      "fitness score at this local optimum: -0.0627327114409\n",
      "fitness score at this local optimum: -0.040399705098\n",
      "fitness score at this local optimum: -0.0394650190677\n",
      "fitness score at this local optimum: -0.0571081137417\n",
      "fitness score at this local optimum: -0.0436712842645\n",
      "fitness score at this local optimum: -0.0441375303545\n",
      "fitness score at this local optimum: -0.0464145410116\n",
      "fitness score at this local optimum: -0.0176910274474\n",
      "fitness score at this local optimum: -0.0508112220746\n",
      "fitness score at this local optimum: -0.0509944167587\n",
      "fitness score at this local optimum: -0.0502510044937\n",
      "fitness score at this local optimum: -0.0422986977391\n",
      "fitness score at this local optimum: -0.0357360397727\n",
      "fitness score at this local optimum: -0.0437712134501\n",
      "fitness score at this local optimum: -0.0406481927854\n",
      "fitness score at this local optimum: -0.0412905640109\n",
      "fitness score at this local optimum: -0.0493113208989\n",
      "fitness score at this local optimum: -0.0535861931624\n",
      "fitness score at this local optimum: -0.0473758076743\n",
      "fitness score at this local optimum: -0.0549770951793\n",
      "fitness score at this local optimum: -0.0515793662211\n",
      "fitness score at this local optimum: -0.0523938504196\n",
      "=====================================================================\n",
      "fitness score at this local optimum: -0.583088631253\n",
      "fitness score at this local optimum: -0.667468771323\n",
      "fitness score at this local optimum: -0.671102418975\n",
      "fitness score at this local optimum: -0.475334049322\n",
      "fitness score at this local optimum: -0.160829165941\n",
      "fitness score at this local optimum: -0.311418884988\n",
      "fitness score at this local optimum: -0.729110382473\n",
      "fitness score at this local optimum: -0.719633872243\n",
      "fitness score at this local optimum: -0.544743565417\n"
     ]
    }
   ],
   "source": [
    "pepg_ad_Logs=dict()\n",
    "\n",
    "for sigma_init_val in [0.1]:\n",
    "    for lr in [0.01,0.1]:\n",
    "        for db in [0.01]:\n",
    "            for opt in [0,1,2,3]:\n",
    "                pepga = PEPGAdaptive(NPARAMS,                         # number of model parameters\n",
    "                sigma_init=sigma_init_val,                 # initial standard deviation\n",
    "                learning_rate=lr ,             # learning rate for standard deviation\n",
    "                learning_rate_decay=0.9999,       # don't anneal the learning rate\n",
    "                popsize=NPOPULATION,             # population size\n",
    "                average_baseline=False,          # set baseline to average of batch\n",
    "                weight_decay=0.00,            # weight decay coefficient\n",
    "                rank_fitness=False,           # use rank rather than fitness numbers\n",
    "                forget_best=False,\n",
    "                option = opt ,\n",
    "                diversity_base = db)\n",
    "                h= batch_debug_solver(pepga,printLog=False)              \n",
    "                print(\"=====================================================================\")\n",
    "                config=Config(popsize=NPOPULATION, learning_rate=lr, sigma_init=sigma_init_val,diversity_base=db)\n",
    "                pepg_ad_Logs[(option,config)]=copy.copy(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pepg_ad0_Logs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start= 30000\n",
    "# end = 60000\n",
    "# setPlot(pepg_v_Logs,\"PEPG-Varaint\",1) \n",
    "\n",
    "start= 0\n",
    "end = 60000\n",
    "setPlot(pepg_a_Logs,\"PEPG-Aadpative\",1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config=Config(popsize=NPOPULATION, learning_rate=0.01, sigma_init=0.1,diversity_base=0)\n",
    "aconfig=Config(popsize=17, learning_rate=0.01, sigma_init=0.1,diversity_base=0.01)\n",
    "lconfig=Config(popsize=17, learning_rate=0.1, sigma_init=0.1,diversity_base=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=dict()\n",
    "# result['PEPG']=pepgLogs[config]\n",
    "result['PEPG_AD0']=pepg_ad0_Logs[aconfig]\n",
    "# result['PEPG_AD0L']=pepg_ad0_Logs[lconfig]\n",
    "result['PEPG_AD1']=pepg_ad1_Logs[aconfig]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDict=dict()\n",
    "labelDict[1]='Loss (mean)'\n",
    "labelDict[0]='Loss (best)'\n",
    "labelDict[2]='Entropy '\n",
    "labelDict[3]='Reward Std'\n",
    "labelDict[4]='Act'\n",
    "\n",
    "def showBest(logs,index):\n",
    "    lgs=[] # for legends \n",
    "    for method in logs.keys():\n",
    "        label=method\n",
    "        h=logs[method]\n",
    "        tline=curvePlot(h[:,:,index],label,start,end)\n",
    "        lgs.append(copy.copy(tline))\n",
    "\n",
    "    plt.xlabel('Generation')\n",
    "    if index in [0,1,3]:\n",
    "        plt.yscale('log')\n",
    "    plt.ylabel(labelDict[index])\n",
    "#     plt.title(title_gen(args))\n",
    "    plt.legend(handles=lgs, loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0 \n",
    "end = 60000\n",
    "showBest(result,0) # best \n",
    "# showBest(result,4) # \n",
    "showBest(result,1)\n",
    "showBest(result,2)\n",
    "showBest(result,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plotsample(sampleIndex,0)\n",
    "# plotsample(sampleIndex,1)\n",
    "# # plotsample(sampleIndex,2)\n",
    "# plotsample(sampleIndex,3)\n",
    "# plotsample(sampleIndex,4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random pick one sample to check action \n",
    "sampleIndex=2\n",
    "epoch=np.linspace(start,end+1,end-start)\n",
    "# plt.plot(epoch,pepga_best[sampleIndex,start:end,-1])\n",
    "# plt.show()\n",
    "\n",
    "def plotsample(sampleIndex,index):\n",
    "    if index<=3:\n",
    "        plt.plot(epoch,pepg_best[sampleIndex,start:end,index],label='PEPG')\n",
    "    plt.plot(epoch,pepgv_best[sampleIndex,start:end,index],label='PEPG_Variant')\n",
    "    plt.plot(epoch,pepga_best[sampleIndex,start:end,index],label='PEPG_Adaptive')\n",
    "    plt.xlabel('Generation')\n",
    "    if index in [0,1,3]:\n",
    "        plt.yscale('log')\n",
    "    plt.ylabel(labelDict[index])\n",
    "    plt.title(\"Sample \"+title_gen(args))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch,np.mean(pepga_best[:,start:end,-1],axis=0))\n",
    "plt.ylabel('Act')\n",
    "plt.show()\n",
    "epoch=np.linspace(start,end+1,end-start)\n",
    "plt.plot(epoch,np.mean(pepg_best[:,start:end,1],axis=0),label='PEPG')\n",
    "plt.plot(epoch,np.mean(pepgv_best[:,start:end,1],axis=0),label='PEPG_Variant')\n",
    "plt.plot(epoch,np.mean(pepga_best[:,start:end,1],axis=0),label='PEPG_Adaptive')\n",
    "plt.legend(loc='best')\n",
    "# plt.yscale('log')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_diff(x):\n",
    "    x =np.array(x)\n",
    "    start = np.array([0])\n",
    "    y = np.concatenate((start,x))\n",
    "    \n",
    "    return (x-y[:-1])[1:]\n",
    "    \n",
    "#     return x-y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.mean(pepg_vadaptive_historys[:,:,2],axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pepg_vadaptive_historys[1,35000:40000,-1])\n",
    "plt.show()\n",
    "sum(pepg_vadaptive_historys[1,35000:40000,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_meanDiff(historys):\n",
    "    return cal_diff(np.mean(historys[:,start:end],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FDiff=cal_diff(pepg_vadaptive_historys[1,:,1])\n",
    "\n",
    "EDiff=cal_diff(pepg_vadaptive_historys[1,:,2])\n",
    "# plt.plot(FDiff,alpha=0.5,color='b')\n",
    "\n",
    "\n",
    "# plt.plot()\n",
    "plt.plot(FDiff,alpha=0.5,color='r')\n",
    "# plt.plot(pepg_vadaptive_historys[1,:,-1],alpha=0.5,color='b')\n",
    "# plt.plot(FDiff/EDiff)\n",
    "# plt.ylim(-0.01,0.01)\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(FDiff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4), dpi=150)\n",
    "start=0\n",
    "end=MAX_ITERATION\n",
    "pepg_line, = plt.plot(pepg_historys[start:end,1], color=\"blue\", linewidth=1.0, linestyle=\"-\", label='PEPG / NES')\n",
    "pepgv_line,= plt.plot([start:end,1], color=\"red\", linewidth=1.0, linestyle=\"-\", label='PEPGV-0.01-19')\n",
    "lgs=[]\n",
    "lgs.append(pepg_line)\n",
    "lgs.append(pepgv_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend(handles=lgs, loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "funcName=\"Rosenbrock\"\n",
    "plt.title(funcName+\"_\"+str(NPARAMS)+\"d\"+\"_population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4), dpi=150)\n",
    "start=0\n",
    "# end=10000\n",
    "end=MAX_ITERATION\n",
    "pepg_line, = plt.plot(pepg_historys[start:end,0], color=\"blue\", linewidth=1.0, linestyle=\"-.\", label='PEPG / NES')\n",
    "pepgv_line,= plt.plot(pepg_variant_historys[start:end,0], color=\"red\", linewidth=1.0, linestyle=\"-\", label='PEPGV-0.01-')\n",
    "pepgTA_line,= plt.plot(pepg_vadaptive_historys[start:end,0], color=\"purple\", linewidth=1.0, linestyle=\"-\", label='PEPGV-0.05-101')\n",
    "lgs=[]\n",
    "lgs.append(pepg_line)\n",
    "lgs.append(pepgv_line)\n",
    "lgs.append(pepgTA_line)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "# plt.yscale('log')\n",
    "plt.legend(handles=lgs, loc='best')\n",
    "funcName=\"Rosenbrock\"\n",
    "plt.title(funcName+\"_\"+str(NPARAMS)+\"d\"+\"_niche\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start,end=0,MAX_ITERATION\n",
    "plt.figure(figsize=(8,4), dpi=150)\n",
    "pepg_line, = plt.plot(pepg_history[start:end,2], color=\"blue\", linewidth=1.0, linestyle=\"-.\", label='PEPG')\n",
    "pepgv_line,= plt.plot(pepgv_history[start:end,2], color=\"red\", linewidth=1.0, linestyle=\"-\", label='PEPGV')\n",
    "lg=[]\n",
    "lg.append(pepg_line)\n",
    "lg.append(pepgv_line)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Entropy')\n",
    "plt.legend(handles=lgs, loc='best')\n",
    "funcName=\"Rosenbrock\"\n",
    "plt.title(funcName+\"_\"+str(NPARAMS)+\"d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sum(pepgv_history[:,-1]))\n",
    "print(pepgv_history[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4), dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=0\n",
    "end=1000\n",
    "pepg_line, = plt.plot(pepg_history[start:end,2], color=\"blue\", linewidth=1.0, linestyle=\"-.\", label='PEPG')\n",
    "pepgv_line,= plt.plot(pepgv_history[start:end,2], color=\"red\", linewidth=1.0, linestyle=\"-\", label='PEPGV')\n",
    "lg=[]\n",
    "lg.append(pepg_line)\n",
    "lg.append(pepgv_line)\n",
    "plt.legend(handles=lgs, loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Entropy')\n",
    "# plt.yscale('log')\n",
    "plt.title(funcName+\"_\"+str(NPARAMS)+\"d\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sum(pepgv_history[:,-1]))\n",
    "plt.plot(pepgv_history[:500,-1],color=\"red\", linewidth=1.0, label='PEPGV')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fool-Act')\n",
    "# plt.yscale('log')\n",
    "plt.show()\n",
    "print(sum(pepgv_history[:500,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pepgv_history[start:500,1],color='red')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
